{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f0_OebPqcwq"
      },
      "source": [
        "Alumno: Fernando Arturo Arevalo Perez-  \n",
        "Numero de Alumno: 323018942  \n",
        "4- 2. Fundamentos de Spark_SQL_DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDYTiqW5TYZq"
      },
      "source": [
        "# Fundamentos de Apache Spark: SQL/DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKgHrskPTYZr"
      },
      "source": [
        "**Spark SQLtrabaja con DataFrames**. Un DataFrame es una **representación relacional de los datos**. Proporciona funciones con capacidades similares a SQL. Además, permite escribir **consultas tipo SQL** para nuestro análisis de datos.\n",
        "\n",
        "Los DataFrames son similares a las tablas relacionales o DataFrames en Python / R auqnue con muchas optimizaciones que se ejecutan de manera \"oculta\" para el usuario. Hay varias formas de crear DataFrames a partir de colecciones, tablas HIVE, tablas relacionales y RDD."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install pyspark"
      ],
      "metadata": {
        "id": "Ia-gZ1a7q74a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install findspark"
      ],
      "metadata": {
        "id": "1bwbo7Arrf6u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Gt1FjfCRTYZs"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pandas as pd\n",
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Mo81n3gsTYZs"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KOjuEjRTYZs"
      },
      "source": [
        "### Crear la sesión de Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "A8Eg2IU8TYZs"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3ipWZiQQTYZs",
        "outputId": "e61a0567-328d-4374-9719-f18053322b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7dbe84dde830>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ef77f6b9af26:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoOWuUF7TYZt"
      },
      "source": [
        "### Crear el DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7qm71HY9TYZt"
      },
      "outputs": [],
      "source": [
        "emp = [(1, \"AAA\", \"dept1\", 1000),\n",
        "    (2, \"BBB\", \"dept1\", 1100),\n",
        "    (3, \"CCC\", \"dept1\", 3000),\n",
        "    (4, \"DDD\", \"dept1\", 1500),\n",
        "    (5, \"EEE\", \"dept2\", 8000),\n",
        "    (6, \"FFF\", \"dept2\", 7200),\n",
        "    (7, \"GGG\", \"dept3\", 7100),\n",
        "    (8, \"HHH\", \"dept3\", 3700),\n",
        "    (9, \"III\", \"dept3\", 4500),\n",
        "    (10, \"JJJ\", \"dept5\", 3400)]\n",
        "\n",
        "dept = [(\"dept1\", \"Department - 1\"),\n",
        "        (\"dept2\", \"Department - 2\"),\n",
        "        (\"dept3\", \"Department - 3\"),\n",
        "        (\"dept4\", \"Department - 4\")\n",
        "\n",
        "       ]\n",
        "\n",
        "df = spark.createDataFrame(emp, [\"id\", \"name\", \"dept\", \"salary\"])\n",
        "\n",
        "deptdf = spark.createDataFrame(dept, [\"id\", \"name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tI_o0BDOTYZt",
        "outputId": "7063cd89-1531-4e78-9d25-9ab216ea6e23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "|  2| BBB|dept1|  1100|\n",
            "|  3| CCC|dept1|  3000|\n",
            "|  4| DDD|dept1|  1500|\n",
            "|  5| EEE|dept2|  8000|\n",
            "|  6| FFF|dept2|  7200|\n",
            "|  7| GGG|dept3|  7100|\n",
            "|  8| HHH|dept3|  3700|\n",
            "|  9| III|dept3|  4500|\n",
            "| 10| JJJ|dept5|  3400|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qozsMabSTYZt"
      },
      "outputs": [],
      "source": [
        "#Crear un df a partir de una tabla de Hive\n",
        "df = spark.table(\"tbl_name\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNLrb4NcTYZu"
      },
      "source": [
        "# Operaciones básicas en DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ70WZBbTYZu"
      },
      "source": [
        "### count\n",
        "* Cuenta el número de filas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iZrTigoxTYZu",
        "outputId": "f93b9d5c-d3da-45c7-b836-cbc8df76f504",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOQXu5nxTYZu"
      },
      "source": [
        "### columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tI9aMtf7TYZu",
        "outputId": "f1e815a8-f6aa-477c-faff-13f9292c2bbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'name', 'dept', 'salary']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiPhishWTYZv"
      },
      "source": [
        "### dtypes\n",
        "** Accede al DataType de columnas dentro del DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h1MH-gHQTYZv",
        "outputId": "94039ace-868e-47d3-9a49-064647fe7304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('id', 'bigint'),\n",
              " ('name', 'string'),\n",
              " ('dept', 'string'),\n",
              " ('salary', 'bigint')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGCLglj5TYZv"
      },
      "source": [
        "### schema\n",
        "** Comprueba cómo Spark almacena el esquema del DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ygU8un90TYZv",
        "outputId": "f869c61e-c372-45f2-e65a-a132b540b23d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('id', LongType(), True), StructField('name', StringType(), True), StructField('dept', StringType(), True), StructField('salary', LongType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "df.schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k648AfQRTYZv"
      },
      "source": [
        "### printSchema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7jWxQSokTYZv",
        "outputId": "54685443-bd1d-49d5-e4c1-d19707d35ecf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- dept: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV5Zvf6KTYZv"
      },
      "source": [
        "### select\n",
        "* Seleccione columnas del DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lgGff5waTYZv",
        "outputId": "10a97041-b496-4ac8-aa23-5a3e8e00ff94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  1| AAA|\n",
            "|  2| BBB|\n",
            "|  3| CCC|\n",
            "|  4| DDD|\n",
            "|  5| EEE|\n",
            "|  6| FFF|\n",
            "|  7| GGG|\n",
            "|  8| HHH|\n",
            "|  9| III|\n",
            "| 10| JJJ|\n",
            "+---+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(\"id\", \"name\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDhAw5Z8TYZw"
      },
      "source": [
        "### filter\n",
        "\n",
        "* Filtrar las filas según alguna condición.\n",
        "* Intentemos encontrar las filas con id = 1.\n",
        "* Hay diferentes formas de especificar la condición."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "j5IyEeOCTYZw",
        "outputId": "dd81974d-2645-4b7d-879c-4f6c020909c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n",
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter(df[\"id\"] == 1).show()\n",
        "df.filter(df.id == 1).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FwtD-w84TYZw",
        "outputId": "440178c1-baac-424a-e964-4bf40b0cb331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n",
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter(col(\"id\") == 1).show()\n",
        "df.filter(\"id = 1\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxnqpw7kTYZw"
      },
      "source": [
        "### drop\n",
        "* Elimina una columna en particular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "zVW6nHULTYZw",
        "outputId": "7f8f73e7-17db-4193-a907-cefa66eb1b64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+------+\n",
            "|name| dept|salary|\n",
            "+----+-----+------+\n",
            "| AAA|dept1|  1000|\n",
            "| BBB|dept1|  1100|\n",
            "+----+-----+------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "newdf = df.drop(\"id\")\n",
        "newdf.show(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2zGTJ3kTYZw"
      },
      "source": [
        "### Aggregations\n",
        "* Podemos usar la función groupBy para agrupar los datos y luego usar la función \"agg\" para realizar la agregación de datos agrupados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JK-f_P2oTYZw",
        "outputId": "e1f63ca4-624e-4e53-c954-c681c854be26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----+----+----+------+\n",
            "| dept|count|  sum| max| min|   avg|\n",
            "+-----+-----+-----+----+----+------+\n",
            "|dept1|    4| 6600|3000|1000|1650.0|\n",
            "|dept2|    2|15200|8000|7200|7600.0|\n",
            "|dept5|    1| 3400|3400|3400|3400.0|\n",
            "|dept3|    3|15300|7100|3700|5100.0|\n",
            "+-----+-----+-----+----+----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "(df.groupBy(\"dept\")\n",
        "    .agg(\n",
        "        count(\"salary\").alias(\"count\"),\n",
        "        sum(\"salary\").alias(\"sum\"),\n",
        "        max(\"salary\").alias(\"max\"),\n",
        "        min(\"salary\").alias(\"min\"),\n",
        "        avg(\"salary\").alias(\"avg\")\n",
        "        ).show()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb2i7qfoTYZw"
      },
      "source": [
        "### Sorting\n",
        "\n",
        "* Ordena los datos según el \"salario\". De forma predeterminada, la clasificación se realizará en orden ascendente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "9N3JMX-vTYZx",
        "outputId": "9e475d59-1712-4b63-fd70-42372872a823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "|  2| BBB|dept1|  1100|\n",
            "|  4| DDD|dept1|  1500|\n",
            "|  3| CCC|dept1|  3000|\n",
            "| 10| JJJ|dept5|  3400|\n",
            "+---+----+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.sort(\"salary\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dXipIftPTYZx",
        "outputId": "0ae51646-bb81-4ded-abb6-c254fc9d2df5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  5| EEE|dept2|  8000|\n",
            "|  6| FFF|dept2|  7200|\n",
            "|  7| GGG|dept3|  7100|\n",
            "|  9| III|dept3|  4500|\n",
            "|  8| HHH|dept3|  3700|\n",
            "+---+----+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sort the data in descending order.\n",
        "df.sort(desc(\"salary\")).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz5VRkd5TYZx"
      },
      "source": [
        "### Columnas derivadas\n",
        "* Podemos usar la función \"withColumn\" para derivar la columna en función de las columnas existentes ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9xfk-En4TYZx",
        "outputId": "282aceba-771f-49ba-e33f-9d11b938c2ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+-----+\n",
            "| id|name| dept|salary|bonus|\n",
            "+---+----+-----+------+-----+\n",
            "|  1| AAA|dept1|  1000|100.0|\n",
            "|  2| BBB|dept1|  1100|110.0|\n",
            "|  3| CCC|dept1|  3000|300.0|\n",
            "|  4| DDD|dept1|  1500|150.0|\n",
            "|  5| EEE|dept2|  8000|800.0|\n",
            "|  6| FFF|dept2|  7200|720.0|\n",
            "|  7| GGG|dept3|  7100|710.0|\n",
            "|  8| HHH|dept3|  3700|370.0|\n",
            "|  9| III|dept3|  4500|450.0|\n",
            "| 10| JJJ|dept5|  3400|340.0|\n",
            "+---+----+-----+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumn(\"bonus\", col(\"salary\") * .1).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KlAQl2eTYZx"
      },
      "source": [
        "### Joins\n",
        "\n",
        "* Podemos realizar varios tipos de combinaciones en múltiples DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKq2jMSqTYZx"
      },
      "source": [
        "![Sin%20t%C3%ADtulo.png](attachment:Sin%20t%C3%ADtulo.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hC9PPrsbTYZx",
        "outputId": "bb11ffc2-c60f-4190-9536-16b6d788bee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+-----+--------------+\n",
            "| id|name| dept|salary|   id|          name|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "|  1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|  2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|  3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|  4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|  5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "|  6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "|  7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|  8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|  9| III|dept3|  4500|dept3|Department - 3|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inner JOIN.\n",
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pMypSwZTYZy"
      },
      "source": [
        "### Left Outer Join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "bxD9bnxJTYZy",
        "outputId": "964666a6-1e5d-437d-b44f-196a7300f5f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+-----+--------------+\n",
            "| id|name| dept|salary|   id|          name|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "|  1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|  2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|  3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|  4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|  5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "| 10| JJJ|dept5|  3400| NULL|          NULL|\n",
            "|  7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|  8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|  9| III|dept3|  4500|dept3|Department - 3|\n",
            "|  6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"], \"left_outer\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxWZw-SOTYZy"
      },
      "source": [
        "### Right Outer Join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aMf7blwmTYZy",
        "outputId": "2bee18ab-17bc-47e4-a039-a4049c087277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+-----+------+-----+--------------+\n",
            "|  id|name| dept|salary|   id|          name|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "|   4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|   3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|   2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|   1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|   6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "|   5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "|   9| III|dept3|  4500|dept3|Department - 3|\n",
            "|   8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|   7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|NULL|NULL| NULL|  NULL|dept4|Department - 4|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"], \"right_outer\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn_WKdj7TYZy"
      },
      "source": [
        "### Full Outer Join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "cyqhcpJmTYZy",
        "outputId": "1e7fd745-536a-4d7a-e1e5-02f0d873f9d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+-----+------+-----+--------------+\n",
            "|  id|name| dept|salary|   id|          name|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "|   1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|   2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|   3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|   4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|   5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "|   6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "|   7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|   8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|   9| III|dept3|  4500|dept3|Department - 3|\n",
            "|NULL|NULL| NULL|  NULL|dept4|Department - 4|\n",
            "|  10| JJJ|dept5|  3400| NULL|          NULL|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"], \"outer\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut-_qwzjTYZz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqlMQsMATYZz"
      },
      "source": [
        "### Consultas SQL\n",
        "* Ejecución de consultas tipo SQL.\n",
        "* También podemos realizar análisis de datos escribiendo consultas similares a SQL. Para realizar consultas similares a SQL, necesitamos registrar el DataFrame como una Vista temporal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Bdrk9VeATYZz",
        "outputId": "f68278eb-8855-47e5-c76f-2964b0022dc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Register DataFrame as Temporary Table\n",
        "df.createOrReplaceTempView(\"temp_table\")\n",
        "\n",
        "# Execute SQL-Like query.\n",
        "spark.sql(\"select * from temp_table where id = 1\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "2JXyF5ncTYZz",
        "outputId": "57c20fa0-8076-4daf-d863-34322945307a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  5|\n",
            "|  1|\n",
            "|  3|\n",
            "|  2|\n",
            "|  4|\n",
            "|  7|\n",
            "|  6|\n",
            "|  9|\n",
            "| 10|\n",
            "|  8|\n",
            "+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select distinct id from temp_table\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "euaWQGqZTYZz",
        "outputId": "dfecb474-26ae-4c57-8cf3-5d20f484cf8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  3| CCC|dept1|  3000|\n",
            "|  4| DDD|dept1|  1500|\n",
            "|  5| EEE|dept2|  8000|\n",
            "|  6| FFF|dept2|  7200|\n",
            "|  7| GGG|dept3|  7100|\n",
            "|  8| HHH|dept3|  3700|\n",
            "|  9| III|dept3|  4500|\n",
            "| 10| JJJ|dept5|  3400|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select * from temp_table where salary >= 1500\").show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJtP2IZlTYZz"
      },
      "source": [
        "### Leyendo la tabla HIVE como DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "t6Jq9GqETYZz"
      },
      "outputs": [],
      "source": [
        "# DB_NAME : Name of the the HIVE Database\n",
        "# TBL_NAME : Name of the HIVE Table\n",
        "\n",
        "\n",
        "df = spark.table(\"DB_NAME\".\"TBL_NAME\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6TI_II8TYZz"
      },
      "source": [
        "### Guardar DataFrame como tabla HIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "qNgnXH8KTYZ0"
      },
      "outputs": [],
      "source": [
        "df.write.saveAsTable(\"DB_NAME.TBL_NAME\")\n",
        "\n",
        "## También podemos seleccionar el argumento \"modo\" con overwrite\", \"append\", \"error\" etc.\n",
        "df.write.saveAsTable(\"DB_NAME.TBL_NAME\", mode=\"overwrite\")\n",
        "\n",
        "# De forma predeterminada, la operación guardará el DataFrame como una tabla interna / administrada de HIVE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "858Nw5WQTYZ0"
      },
      "source": [
        "### Guardar el DataFrame como una tabla externa HIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcXaQuQhTYZ0"
      },
      "outputs": [],
      "source": [
        "df.write.saveAsTable(\"DB_NAME.TBL_NAME\", path=<location_of_external_table>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYxk9Ld6TYZ0"
      },
      "source": [
        "### Crea un DataFrame a partir de un archivo CSV\n",
        "* Podemos crear un DataFrame usando un archivo CSV y podemos especificar varias opciones como un separador, encabezado, esquema, inferSchema y varias otras opciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcCis18jTYZ0"
      },
      "outputs": [],
      "source": [
        " df = spark.read.csv(\"path_to_csv_file\", sep=\"|\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l87u7lneTYZ0"
      },
      "source": [
        "### Guardar un DataFrame como un archivo CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8fO1lAhTYZ0"
      },
      "outputs": [],
      "source": [
        "df.write.csv(\"path_to_CSV_File\", sep=\"|\", header=True, mode=\"overwrite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOCuAEobTYZ0"
      },
      "source": [
        "### Crea un DataFrame a partir de una tabla relacional\n",
        "* Podemos leer los datos de bases de datos relacionales usando una URL JDBC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpHAlInPTYZ0"
      },
      "outputs": [],
      "source": [
        "# url : a JDBC URL of the form jdbc:subprotocol:subname\n",
        "# TBL_NAME : Name of the relational table.\n",
        "# USER_NAME : user name to connect to DataBase.\n",
        "# PASSWORD: password to connect to DataBase.\n",
        "\n",
        "\n",
        "relational_df = spark.read.format('jdbc')\n",
        "                        .options(url=url, dbtable= <TBL_NAME>, user= <USER_NAME>, password = <PASSWORD>)\n",
        "                        .load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1JH_PahTYZ1"
      },
      "source": [
        "### Guardar el DataFrame como una tabla relacional\n",
        "* Podemos guardar el DataFrame como una tabla relacional usando una URL JDBC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj3G9Un8TYZ1"
      },
      "outputs": [],
      "source": [
        "# url : a JDBC URL of the form jdbc:subprotocol:subname\n",
        "# TBL_NAME : Name of the relational table.\n",
        "# USER_NAME : user name to connect to DataBase.\n",
        "# PASSWORD: password to connect to DataBase.\n",
        "\n",
        "\n",
        " relational_df.write.format('jdbc')\n",
        "                    .options(url=url, dbtable= <TBL_NAME>, user= <USER_NAME>, password = <PASSWORD>)\n",
        "                    .mode('overwrite')\n",
        "                    .save()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}